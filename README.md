Phase 1 - Problem Definition
1.1 Broad Goals
1.2 Data Source
1.3 Problem Statement
Phase 2 - Data Gathering
2.1 define functions to parse sound files
2.2 convert stereo sound to mono
2.3 data cleaning
Phase 3 - Exploratory Data Analysis
3.1 Sampling Rates
3.2 MFCC
3.3 Chroma
3.4 MEL
3.5 Tagged Emotions
Phase 4 - Modeling
4.1 Train/Test/Split
4.2 Pipeline Setup
4.3 Gridsearch
4.4 Examine Misclassifications
4.5 Parameter Tuning
Phase 5 - Model Analysis
5.0 Baseline Score 
5.1 Compare Accuracy Scores
5.2 Compare AUC-ROC Curves
5.3 Production Model
Phase 6 - Conclusions
6.0 Revisit 1.3 Problem Statement 
6.1 Conclusions
6.2 Recommendations for Further Research
6.3 Credits/References
    Livingstone SR, Russo FA (2018) The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English. PLoS ONE 13(5): e0196391. https://doi.org/10.1371/journal.pone.0196391.
    
    EDA Segment and comprehension of the Short Term Fuorier Transform inspired by 
    https://jackschaedler.github.io/circles-sines-signals